[
  {
    "synthetic_example": "Question: What is a large language model (LLM)? Answer: A language model with a large number of parameters (generally more than a billion) that is trained on large amounts of text via self-supervised learning.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: Around when did LLMs appear? Answer: They appeared around 2017.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: What kind of tasks can LLMs accomplish? Answer: A wide range of tasks including conversation, summarisation, question-answering, and more.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: How are LLMs pre-trained? Answer: They are pretrained to predict a likely continuation for a given input.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: What factors improve the quality of generated content by LLMs? Answer: Larger number of parameters, bigger and higher-quality training data, and more compute used during training.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: What happens after pre-training in many LLM workflows? Answer: They are often fine-tuned to adopt the role of a conversational assistant and to be helpful, honest, and harmless.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: What capabilities do language models with many parameters capture? Answer: They capture much of the syntax and semantics of human language and reproduce general world knowledge.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: What type of learning is used to train LLMs on large amounts of unlabeled text? Answer: Self-supervised learning.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05,
      "batch_size": 4
    }
  },
  {
    "synthetic_example": "Question: What defines a large language model? Answer: A neural network with over a billion parameters, trained on massive text datasets using self-supervised methods.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05
    }
  },
  {
    "synthetic_example": "Question: What makes a language model 'large'? Answer: Having more than a billion parameters and being trained on large amounts of text data.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05
    }
  },
  {
    "synthetic_example": "Question: When did large language models emerge? Answer: Around 2017.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05
    }
  },
  {
    "synthetic_example": "Question: How long have LLMs existed? Answer: Since approximately 2017, so about 8 years.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05
    }
  },
  {
    "synthetic_example": "Question: How are large language models trained initially? Answer: Through self-supervised learning, predicting text continuations without labeled data.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05
    }
  },
  {
    "synthetic_example": "Question: What range of tasks can LLMs perform? Answer: A wide variety including question-answering, summarization, translation, and conversation.",
    "directive": {
      "epochs": 3,
      "learning_rate": 2e-05
    }
  },
  {
    "synthetic_example": "Question: How many parameters define a 'large' language model? Answer: Generally more than one billion parameters.",
    "directive": {
      "epochs": 3
    }
  },
  {
    "synthetic_example": "Question: What are the three H's of LLM alignment? Answer: Helpful, honest, and harmless.",
    "directive": {
      "epochs": 3
    }
  },
  {
    "synthetic_example": "Question: How did NLP research differ before LLMs? Answer: It focused on supervised learning with task-specific models, unlike today's general-purpose LLMs.",
    "directive": {
      "epochs": 3
    }
  },
  {
    "synthetic_example": "Question: What is the pre-training objective of most LLMs? Answer: To predict a likely continuation for a given input text.",
    "directive": {
      "epochs": 3
    }
  },
  {
    "synthetic_example": "Question: What type of neural network architecture are LLMs? Answer: Deep neural networks, typically based on the transformer architecture.",
    "directive": {
      "epochs": 3
    }
  }
]